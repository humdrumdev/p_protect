{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560 1440\n"
     ]
    }
   ],
   "source": [
    "width, height = pyautogui.size()\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 523\n"
     ]
    }
   ],
   "source": [
    "currentMouseX, currentMouseY = pyautogui.position()\n",
    "\n",
    "print(currentMouseX, currentMouseY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.moveTo(100, 150)\n",
    "\n",
    "pyautogui.click()\n",
    "pyautogui.click(100, 200) \n",
    "# pyautogui.click('button.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:231] . file in archive is not in a subdirectory archive/: plant-disease-model.pth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hel-moud/Downloads/plantprotect/leaf_id.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hel-moud/Downloads/plantprotect/leaf_id.ipynb#ch0000004?line=118'>119</a>\u001b[0m PATH2 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./plant-disease-model-complete.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hel-moud/Downloads/plantprotect/leaf_id.ipynb#ch0000004?line=119'>120</a>\u001b[0m \u001b[39m# torch.save(model, PATH2)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hel-moud/Downloads/plantprotect/leaf_id.ipynb#ch0000004?line=120'>121</a>\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/hel-moud/Downloads/plantprotect/leaf_id.ipynb#ch0000004?line=121'>122</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(PATH2, map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hel-moud/Downloads/plantprotect/leaf_id.ipynb#ch0000004?line=122'>123</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/serialization.py:706\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=703'>704</a>\u001b[0m orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=704'>705</a>\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=705'>706</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=706'>707</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=707'>708</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=708'>709</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=709'>710</a>\u001b[0m         opened_file\u001b[39m.\u001b[39mseek(orig_position)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/serialization.py:1054\u001b[0m, in \u001b[0;36m_is_torchscript_zip\u001b[0;34m(zip_file)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=1052'>1053</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_torchscript_zip\u001b[39m(zip_file):\n\u001b[0;32m-> <a href='file:///Users/hel-moud/Library/Python/3.9/lib/python/site-packages/torch/serialization.py?line=1053'>1054</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mconstants.pkl\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m zip_file\u001b[39m.\u001b[39;49mget_all_records()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:231] . file in archive is not in a subdirectory archive/: plant-disease-model.pth"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid       # for data checking\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F  # for functions for calculating loss\n",
    "from PIL import Image           # for checking images\n",
    "from torch.utils.data import DataLoader  # for dataloaders\n",
    "import torch.nn as nn           # for creating  neural networks\n",
    "import matplotlib.pyplot as plt\n",
    "import torch                    # Pytorch module\n",
    "import pandas as pd             # for working with dataframes\n",
    "import numpy as np              # for numerical computationss\n",
    "import os                       # for working with files\n",
    "PATH = './plant-disease-model.pth'\n",
    "# for plotting informations on graph and images using tensors\n",
    "# for transforming images into tensors\n",
    "# for working with classes and images\n",
    "# for getting the summary of our model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# base class for the model\n",
    "# for calculating the accuracy\n",
    "# Residual Block code implementation\n",
    "\n",
    "\n",
    "class SimpleResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        # ReLU can be applied before or after adding the input\n",
    "        return self.relu2(out) + x\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                   # Generate prediction\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)          # Calculate accuracy\n",
    "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
    "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
    "        # Combine accuracies\n",
    "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n",
    "\n",
    "\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "              nn.BatchNorm2d(out_channels),\n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# resnet architecture\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True)  # out_dim : 128 x 64 x 64\n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "\n",
    "        self.conv3 = ConvBlock(128, 256, pool=True)  # out_dim : 256 x 16 x 16\n",
    "        self.conv4 = ConvBlock(256, 512, pool=True)  # out_dim : 512 x 4 x 44\n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(512, num_diseases))\n",
    "\n",
    "    def forward(self, xb):  # xb is the loaded batch\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "# model = ResNet9(3, 38)\n",
    "# model.load_state_dict(state_dict = torch.load(\n",
    "#     PATH), map_location = torch.device(('cpu')))\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "PATH2 = './plant-disease-model-complete.pth'\n",
    "# torch.save(model, PATH2)\n",
    "# model.eval()\n",
    "model = torch.load(PATH2, map_location=torch.device('cpu'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AppleCedarRust1.JPG',\n",
       " 'AppleCedarRust2.JPG',\n",
       " 'AppleCedarRust3.JPG',\n",
       " 'AppleCedarRust4.JPG',\n",
       " 'AppleScab1.JPG',\n",
       " 'AppleScab2.JPG',\n",
       " 'AppleScab3.JPG',\n",
       " 'CornCommonRust1.JPG',\n",
       " 'CornCommonRust2.JPG',\n",
       " 'CornCommonRust3.JPG',\n",
       " 'PotatoEarlyBlight1.JPG',\n",
       " 'PotatoEarlyBlight2.JPG',\n",
       " 'PotatoEarlyBlight3.JPG',\n",
       " 'PotatoEarlyBlight4.JPG',\n",
       " 'PotatoEarlyBlight5.JPG',\n",
       " 'PotatoHealthy1.JPG',\n",
       " 'PotatoHealthy2.JPG',\n",
       " 'TomatoEarlyBlight1.JPG',\n",
       " 'TomatoEarlyBlight2.JPG',\n",
       " 'TomatoEarlyBlight3.JPG',\n",
       " 'TomatoEarlyBlight4.JPG',\n",
       " 'TomatoEarlyBlight5.JPG',\n",
       " 'TomatoEarlyBlight6.JPG',\n",
       " 'TomatoHealthy1.JPG',\n",
       " 'TomatoHealthy2.JPG',\n",
       " 'TomatoHealthy3.JPG',\n",
       " 'TomatoHealthy4.JPG',\n",
       " 'TomatoYellowCurlVirus1.JPG',\n",
       " 'TomatoYellowCurlVirus2.JPG',\n",
       " 'TomatoYellowCurlVirus3.JPG',\n",
       " 'TomatoYellowCurlVirus4.JPG',\n",
       " 'TomatoYellowCurlVirus5.JPG',\n",
       " 'TomatoYellowCurlVirus6.JPG']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = \"\"\n",
    "test = ImageFolder(test_dir, transform=transforms.ToTensor())\n",
    "# since images in test folder are in alphabetical order\n",
    "test_images = sorted(os.listdir(test_dir + '/test'))\n",
    "test_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(img, model):\n",
    "    \"\"\"Converts image to array and return the predicted class\n",
    "        with highest probability\"\"\"\n",
    "    # Convert to a batch of 1\n",
    "    if torch.cuda.is_available():\n",
    "        xb = to_device(img.unsqueeze(0), device)\n",
    "    else:\n",
    "        xb = img.unsqueeze(0)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "\n",
    "    return train.classes[preds[0].item()]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
